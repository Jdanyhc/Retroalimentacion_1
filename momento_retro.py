# -*- coding: utf-8 -*-
"""Momento_retro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UyEaVtjC0EF9223BZ5nx2wOOeFn-PTR8

JOSHUA DANIEL HERNANDEZ CORONADO A01750800
"""

#librerias utilizadas
import pandas as pd 
import numpy as np
import random
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive # Montamos el drive para tener acceso a mis datos
drive.mount('/content/drive')

cd "/content/drive/My Drive/Concentracion/RETO CONCENTRACION ETAPA 1"

df = pd.read_csv("Automobile.csv").drop_duplicates()#lee y elimina los duplicados del dataset

df.shape

df.info()

df.isnull().sum()

df.replace(to_replace="?",value=np.NaN,inplace = True)#Se sustituye el valor de ? por una casilla de valor vacio

df.isnull().sum()

df.info()

#Pasamos los valores que se leen de manera erronea como string pero son numericos
df["wheel-base"] = df["wheel-base"].astype(int)
df["price"] = df["price"].astype(float)
df["horsepower"] = df["horsepower"].astype(float)
df["peak-rpm"] = df["peak-rpm"].astype(float)
df["bore"] = df["bore"].astype(float)
df["stroke"] = df["stroke"].astype(float)
df["normalized-losses"] = df["normalized-losses"].astype(float)

df.info()

#importamos de sklearn preprocessing
from sklearn import preprocessing
# se carga una la funcion que labelEncoder
label_encoder = preprocessing.LabelEncoder()
#La funcion LabelEncoder nos permite pasar los valores unicos a valores numericos y categorizar dichas variables 

# Las siguientes variables seran categorizadas y cada valor unico sera remplazado con un valor respectivo
df['make'] = label_encoder.fit_transform(df['make'])
df["fuel-type"] = label_encoder.fit_transform(df["fuel-type"])
df["aspiration"] = label_encoder.fit_transform(df["aspiration"])
df["engine-location"] = label_encoder.fit_transform(df["engine-location"])
df["engine-type"] = label_encoder.fit_transform(df["engine-type"])
df["num-of-cylinders"] = label_encoder.fit_transform(df["num-of-cylinders"])
df["fuel-system"] = label_encoder.fit_transform(df["fuel-system"])
df["body-style"] = label_encoder.fit_transform(df["body-style"])
df["number-of-doors"] = label_encoder.fit_transform(df["number-of-doors"])
df["drive-wheels"] = label_encoder.fit_transform(df["drive-wheels"])

df.info()

from sklearn.model_selection import train_test_split

train,test = train_test_split(df,test_size=0.25, random_state=42)

test.shape

train.shape

#valores de la moda, se calcula la moda para las variables que se consideran categoricas y lo requieren
modeFuel = train["fuel-system"].mode()[0]
modeCylinders = train["num-of-cylinders"].mode()[0]
modeEngine = train["engine-type"].mode()[0]
modeDoors = train["number-of-doors"].mode()[0]
modeMake = train["make"].mode()[0]

#valores de moda de test
modeFuel_t = test["fuel-system"].mode()[0]
modeCylinders_t = test["num-of-cylinders"].mode()[0]
modeEngine_t = test["engine-type"].mode()[0]
modeDoors_t = test["number-of-doors"].mode()[0]
modeMake_t = test["make"].mode()[0]

# Se rellanan los eventos con NA con la moda
train["fuel-system"].fillna(modeFuel,inplace = True)
train["num-of-cylinders"].fillna(modeCylinders,inplace = True)
train["engine-type"].fillna(modeEngine,inplace = True)
train["number-of-doors"].fillna(modeDoors,inplace = True)
train["make"].fillna(modeMake,inplace = True)

test["fuel-system"].fillna(modeFuel_t,inplace = True)
test["num-of-cylinders"].fillna(modeCylinders_t,inplace = True)
test["engine-type"].fillna(modeEngine_t,inplace = True)
test["number-of-doors"].fillna(modeDoors_t,inplace = True)
test["make"].fillna(modeMake_t,inplace = True)

#Valores de la media
Avg_peak_rpm = train["peak-rpm"].mean() 
Avg_horsepower = train["horsepower"].mean()
Avg_stroke = train["stroke"].mean() 
Avg_normalized_losses = train["normalized-losses"].mean() 
Avg_bore = train["bore"].mean()
Avg_price = train["price"].mean()

#Valores de la media
Avg_peak_rpm_t = test["peak-rpm"].mean() 
Avg_horsepower_t = test["horsepower"].mean()
Avg_stroke_t = test["stroke"].mean() 
Avg_normalized_losses_t = test["normalized-losses"].mean() 
Avg_bore_t = test["bore"].mean()
Avg_price_t = test["price"].mean()

#Se rellenan los valores de con la media para valores numericos
train["peak-rpm"].fillna(Avg_peak_rpm,inplace = True)
train["horsepower"].fillna(Avg_horsepower,inplace = True)
train["stroke"].fillna(Avg_stroke,inplace = True)
train["normalized-losses"].fillna(Avg_normalized_losses,inplace = True)
train["bore"].fillna(Avg_bore,inplace = True)
train["price"].fillna(Avg_price,inplace = True)

#Se rellenan los valores de con la media para valores numericos
test["peak-rpm"].fillna(Avg_peak_rpm_t,inplace = True)
test["horsepower"].fillna(Avg_horsepower_t,inplace = True)
test["stroke"].fillna(Avg_stroke_t,inplace = True)
test["normalized-losses"].fillna(Avg_normalized_losses_t,inplace = True)
test["bore"].fillna(Avg_bore_t,inplace = True)
test["price"].fillna(Avg_price_t,inplace = True)

test.isnull().sum()

train.isnull().sum()

train.info()

test.info()

#Se genera un mapa de calor para el analisis de correlacion
plt.figure(figsize=(45, 35))
sns.heatmap(train.corr(), annot=True)

#Se genera un mapa de calor para el analisis de correlacion
plt.figure(figsize=(45, 35))
sns.heatmap(test.corr(), annot=True)

from sklearn.model_selection import train_test_split

from sklearn.preprocessing import StandardScaler

X_train = train.drop("price",axis = 1) # seleccionamos todos las columnas menos la de price
y_train = train["price"] # seleccionamos la columna de price
X_test = test.drop("price",axis = 1)
y_test = test["price"]

#Se estandarizan los datos
sc = StandardScaler()
X_train_stand = sc.fit_transform(X_train)
X_test_stand = sc.transform(X_test)

"""##Modelos"""

from sklearn.ensemble import RandomForestRegressor #se importa random forest y se crea el modelo base
algoritmo = RandomForestRegressor(random_state=42)

algoritmo.fit(X_train_stand, y_train) # se entrena el modelo

y_pred = algoritmo.predict(X_test_stand) #Se calculan las predicciones

from sklearn.metrics import mean_squared_error #calculo del error

mse = mean_squared_error(y_test, y_pred)
rmse = mse**.5
print(mse)
print(rmse)

# Se muestran los valores obtenido del modelo utilizando el set de entrenamiento y el de test
print("Score in training")
print("---------------------------------")
score_train = algoritmo.score(X_train_stand, y_train)
print(score_train)
print("---------------------------------")

print("Score in test")
print("---------------------------------")
score_train = algoritmo.score(X_test_stand, y_test)
print(score_train)
print("---------------------------------")

"""Debido a los resultados obtenido con el score podemos ver que cuando utiliza los datos de entrenamiento el algoritmo obtiene un score de .9758 lo que es un buen score sin embargo a la hora de probar con el set de test podemos ver que dicho score baja hasta el .9178 lo que nos indica que puede a existir un overfitting por lo que se puede procedecer a realizar un crossvalidation, aun asi es importante recalcar que en este caso se debe a que existen pocos datos de train."""

from sklearn.model_selection import cross_val_score

dt_scores = cross_val_score(algoritmo, X_train, y_train, cv = 5)
print("mean cross validation score: {}".format(np.mean(dt_scores)))
print("score without cv: {}".format(algoritmo.score(X_train, y_train)))

"""Con el calculo del cross validation score podemos estar mas seguro y tenemos mas certeza del buen funcionamiento de nuestro algortimo ya que obtenemos un valor de .8437 que aunque no es el mejor score es muy bueno para predecir los precios de los auto segun las caracteristicas de nuestro dataset"""

from sklearn.metrics import r2_score
print(r2_score(y_test, algoritmo.predict(X_test)))
print(algoritmo.score(X_test, y_test)) # se obtienen los valores de r2 para conocer el error

